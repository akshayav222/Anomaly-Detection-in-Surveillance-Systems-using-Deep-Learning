{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "max_frames = 30  # Max frames per video\n",
    "frame_size = (64, 64)  # Frame size\n",
    "num_classes = 2  # Number of classes\n",
    "frame_sampling_rate = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load video data from directories\n",
    "def load_videos_from_directory(directory):\n",
    "    videos = []\n",
    "    labels = []\n",
    "    class_mapping = {name: idx for idx, name in enumerate(os.listdir(directory))}  # Map folder names to indices\n",
    "    for label in class_mapping.keys():\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        if os.path.isdir(label_dir):\n",
    "            for video_file in os.listdir(label_dir):\n",
    "                if video_file.endswith('.mp4'):\n",
    "                    video_path = os.path.join(label_dir, video_file)\n",
    "                    # Load and preprocess video\n",
    "                    frames = load_and_preprocess_video(video_path, frame_sampling_rate)\n",
    "                    if frames is not None:\n",
    "                        videos.append(frames)\n",
    "                        labels.append(class_mapping[label])  # Use the mapped index\n",
    "    return np.array(videos), np.array(labels)\n",
    "\n",
    "# Function to load and preprocess individual videos\n",
    "def load_and_preprocess_video(video_path, frame_sampling_rate):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % frame_sampling_rate == 0:  # Sample every nth frame\n",
    "            frame = cv2.resize(frame, frame_size)\n",
    "            frames.append(frame / 255.0)  # Normalize pixel values\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Pad or truncate frames to max_frames\n",
    "    if len(frames) < max_frames:\n",
    "        frames += [np.zeros(frame_size + (3,))] * (max_frames - len(frames))  # Pad with zeros\n",
    "    return np.array(frames)[:max_frames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "X_train, y_train = load_videos_from_directory('/content/drive/My Drive/archive/TrimedDataset/Train')\n",
    "X_test, y_test = load_videos_from_directory('/content/drive/My Drive/archive/TrimedDataset/Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of unique classes\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Print the number of classes to verify\n",
    "print(\"Number of classes:\", num_classes)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Check shapes\n",
    "print(\"X_train shape:\", X_train.shape)  # Should be (num_samples, max_frames, 64, 64, 3)\n",
    "print(\"y_train shape:\", y_train.shape)  # Should be (num_samples, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 3D CNN model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(max_frames, frame_size[0], frame_size[1], 3)))\n",
    "model.add(Conv3D(32, (3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Conv3D(128, (3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "\n",
    "class VideoDataGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size=16, shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = self.X[indices]\n",
    "        y_batch = self.y[indices]\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "# Create the data generator\n",
    "train_generator = VideoDataGenerator(X_train, y_train, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('3d_cnn_model2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from IPython.display import Audio, display  # Import Audio from IPython\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('3d_cnn_model2.keras')\n",
    "\n",
    "# Define video processing parameters\n",
    "frame_size = (64, 64)  # Resize frames to this size\n",
    "max_frames = 30        # Maximum number of frames to sample\n",
    "frame_sampling_rate = 1  # Sample every nth frame\n",
    "\n",
    "def load_and_preprocess_video(video_path):\n",
    "    \"\"\"Load and preprocess video for anomaly detection.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % frame_sampling_rate == 0:\n",
    "            # Resize and normalize frame\n",
    "            frame = cv2.resize(frame, frame_size)\n",
    "            frames.append(frame / 255.0)  # Normalize pixel values\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Pad or truncate frames to fit max_frames\n",
    "    if len(frames) < max_frames:\n",
    "        frames += [np.zeros(frame_size + (3,))] * (max_frames - len(frames))  # Padding\n",
    "    else:\n",
    "        frames = frames[:max_frames]  # Truncating\n",
    "\n",
    "    return np.array(frames)\n",
    "\n",
    "def detect_anomaly(video_path):\n",
    "    \"\"\"Process the video and detect anomalies.\"\"\"\n",
    "    video_frames = load_and_preprocess_video(video_path)\n",
    "    video_frames = np.expand_dims(video_frames, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(video_frames)\n",
    "\n",
    "    # Normalize predictions to range 0-1\n",
    "    prediction_normalized = prediction / np.sum(prediction, axis=1, keepdims=True)\n",
    "\n",
    "    print(\"Normalized Prediction:\", prediction_normalized)\n",
    "\n",
    "    # Check for anomaly (assuming the prediction output is structured correctly)\n",
    "    if prediction_normalized[0][4] > 0.5:  # Adjust the index based on your model's output\n",
    "        print(\"Anomaly detected!\")\n",
    "        # Play the warning sound using IPython display\n",
    "        display(Audio('/content/drive/My Drive/sound.mp3', autoplay=True))  # Use .mp3 or .wav\n",
    "    else:\n",
    "        print(\"No anomaly detected.\")\n",
    "        print(prediction_normalized[0][4])\n",
    "\n",
    "# Use the function with a video file\n",
    "video_path = '/content/drive/My Drive/footage3.mp4'  # Path to the input video file\n",
    "detect_anomaly(video_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from IPython.display import Audio,display\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model('3d_cnn_model2.keras')  # Update with your model path\n",
    "\n",
    "def load_and_preprocess_video(video_path, frame_sampling_rate=5, max_frames=30):\n",
    "    # Load and preprocess the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if count % frame_sampling_rate == 0:\n",
    "            frame = cv2.resize(frame, (64, 64))\n",
    "            frames.append(frame / 255.0)  # Normalize pixel values\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    # Pad frames if necessary\n",
    "    while len(frames) < max_frames:\n",
    "        frames.append(np.zeros((64, 64, 3)))  # Add zero frames to reach max_frames\n",
    "\n",
    "    return np.array(frames)\n",
    "\n",
    "def detect_anomaly(video_path):\n",
    "    # Load and preprocess the video\n",
    "    video_data = load_and_preprocess_video(video_path)\n",
    "\n",
    "    # Expand dimensions to match model input shape\n",
    "    video_data = np.expand_dims(video_data, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(video_data)\n",
    "\n",
    "    # Normalize predictions\n",
    "    prediction_normalized = predictions / np.sum(predictions)\n",
    "\n",
    "    # Scale predictions to a range of 0.1 to 1.0\n",
    "    min_val = np.min(prediction_normalized)\n",
    "    max_val = np.max(prediction_normalized)\n",
    "\n",
    "    desired_min = 0.1\n",
    "    desired_max = 1.0\n",
    "\n",
    "    scaled_predictions = ((prediction_normalized - min_val) / (max_val - min_val)) * (desired_max - desired_min) + desired_min\n",
    "\n",
    "    # Print scaled predictions\n",
    "    print(\"Scaled Predictions:\", scaled_predictions)\n",
    "\n",
    "    # Check the value at index 4 (assuming you want to check the 5th class)\n",
    "    if scaled_predictions[0][4] < 0.2:  # Adjust the threshold as needed\n",
    "        print(\"Anomaly detected!\")\n",
    "        # Play a warning sound\n",
    "        display(Audio('/content/drive/My Drive/sound.mp3', autoplay=True)) # Update with your sound file path\n",
    "        print(scaled_predictions[0][4])\n",
    "    else:\n",
    "        print(\"No anomaly detected.\")\n",
    "        print(scaled_predictions[0][4])\n",
    "\n",
    "# Use the function with a video file\n",
    "video_path = '/content/drive/My Drive/footage6.mp4'  # Path to the input video file\n",
    "detect_anomaly(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls '/content/drive/My Drive/archive/TrimedDataset/Test'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
